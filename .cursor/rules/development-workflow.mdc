---
description:
globs:
alwaysApply: false
---
# FusionAI å¼€å‘å·¥ä½œæµæŒ‡å—

## ğŸš€ å¼€å‘ç”Ÿå‘½å‘¨æœŸ

### é¡¹ç›®åˆå§‹åŒ–æµç¨‹
```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd fusionai

# 2. ç¯å¢ƒé…ç½®
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# æˆ– .venv\Scripts\activate  # Windows

# 3. ä¾èµ–å®‰è£…
uv sync  # æ¨èä½¿ç”¨uv
# æˆ–è€… pip install -e .

# 4. ç¯å¢ƒå˜é‡é…ç½®
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œæ·»åŠ å¿…è¦çš„APIå¯†é’¥

# 5. æ•°æ®åº“åˆå§‹åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
python scripts/init_db.py

# 6. å¯åŠ¨å¼€å‘æœåŠ¡å™¨
python server.py
```

## ğŸ”„ æ ‡å‡†å¼€å‘æµç¨‹

### åŠŸèƒ½å¼€å‘å¾ªç¯
```mermaid
graph TD
    A[åˆ›å»ºåŠŸèƒ½åˆ†æ”¯] --> B[ç¼–å†™ä»£ç ]
    B --> C[ç¼–å†™å•å…ƒæµ‹è¯•]
    C --> D[è¿è¡Œæµ‹è¯•å¥—ä»¶]
    D --> E{æµ‹è¯•é€šè¿‡?}
    E -->|å¦| B
    E -->|æ˜¯| F[ä»£ç æ ¼å¼åŒ–]
    F --> G[é™æ€ä»£ç æ£€æŸ¥]
    G --> H[æäº¤ä»£ç ]
    H --> I[åˆ›å»ºPR]
    I --> J[ä»£ç å®¡æŸ¥]
    J --> K{å®¡æŸ¥é€šè¿‡?}
    K -->|å¦| B
    K -->|æ˜¯| L[åˆå¹¶ä¸»åˆ†æ”¯]
    L --> M[éƒ¨ç½²æµ‹è¯•ç¯å¢ƒ]
```

### åˆ†æ”¯ç®¡ç†ç­–ç•¥
```bash
# ä¸»è¦åˆ†æ”¯
main          # ç”Ÿäº§åˆ†æ”¯ï¼Œç¨³å®šç‰ˆæœ¬
develop       # å¼€å‘åˆ†æ”¯ï¼Œé›†æˆæ–°åŠŸèƒ½
hotfix/*      # ç´§æ€¥ä¿®å¤åˆ†æ”¯
feature/*     # åŠŸèƒ½å¼€å‘åˆ†æ”¯
release/*     # å‘å¸ƒå‡†å¤‡åˆ†æ”¯

# åˆ†æ”¯åˆ›å»ºç¤ºä¾‹
git checkout develop
git pull origin develop
git checkout -b feature/add-document-analyzer

# å¼€å‘å®Œæˆå
git add .
git commit -m "feat: add document analyzer tool"
git push origin feature/add-document-analyzer
```

## ğŸ› ï¸ æ—¥å¸¸å¼€å‘ä»»åŠ¡

### ä»£ç å¼€å‘è§„èŒƒ
```python
# 1. åˆ›å»ºæ–°åŠŸèƒ½æ¨¡å—
# æ–‡ä»¶: src/tools/document_analyzer.py

"""
æ–‡æ¡£åˆ†æå·¥å…·

æä¾›æ–‡æ¡£å†…å®¹åˆ†æã€å…³é”®è¯æå–ã€æ‘˜è¦ç”Ÿæˆç­‰åŠŸèƒ½ã€‚
"""

import logging
from typing import Dict, List, Optional
from pathlib import Path

from ..utils.decorators import tool_error_handler, performance_monitor
from .base import BaseTool

logger = logging.getLogger(__name__)

class DocumentAnalyzer(BaseTool):
    """æ–‡æ¡£åˆ†æå™¨"""
    
    def __init__(self):
        super().__init__()
        self.name = "document_analyzer"
        self.description = "åˆ†ææ–‡æ¡£å†…å®¹å¹¶æå–å…³é”®ä¿¡æ¯"
    
    @tool_error_handler
    @performance_monitor
    async def analyze_document(self, file_path: str, options: Dict = None) -> Dict:
        """åˆ†ææ–‡æ¡£å†…å®¹
        
        Args:
            file_path: æ–‡æ¡£æ–‡ä»¶è·¯å¾„
            options: åˆ†æé€‰é¡¹é…ç½®
            
        Returns:
            Dict: åˆ†æç»“æœ
        """
        options = options or {}
        
        # å®ç°åˆ†æé€»è¾‘
        result = {
            "summary": "æ–‡æ¡£æ‘˜è¦...",
            "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],
            "sentiment": "positive",
            "language": "zh"
        }
        
        logger.info(f"Document analysis completed for {file_path}")
        return result
```

### æµ‹è¯•å¼€å‘è§„èŒƒ
```python
# æ–‡ä»¶: tests/test_document_analyzer.py

import pytest
from pathlib import Path
from unittest.mock import Mock, patch

from src.tools.document_analyzer import DocumentAnalyzer

class TestDocumentAnalyzer:
    """æ–‡æ¡£åˆ†æå™¨æµ‹è¯•"""
    
    @pytest.fixture
    def analyzer(self):
        """åˆ›å»ºåˆ†æå™¨å®ä¾‹"""
        return DocumentAnalyzer()
    
    @pytest.fixture
    def sample_document(self, tmp_path):
        """åˆ›å»ºæµ‹è¯•æ–‡æ¡£"""
        doc_file = tmp_path / "test.txt"
        doc_file.write_text("è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ï¼ŒåŒ…å«ä¸€äº›ç¤ºä¾‹å†…å®¹ã€‚")
        return str(doc_file)
    
    async def test_analyze_document_success(self, analyzer, sample_document):
        """æµ‹è¯•ï¼šæˆåŠŸåˆ†ææ–‡æ¡£"""
        result = await analyzer.analyze_document(sample_document)
        
        assert "summary" in result
        assert "keywords" in result
        assert isinstance(result["keywords"], list)
        assert "sentiment" in result
    
    async def test_analyze_document_invalid_file(self, analyzer):
        """æµ‹è¯•ï¼šåˆ†æä¸å­˜åœ¨çš„æ–‡ä»¶"""
        with pytest.raises(FileNotFoundError):
            await analyzer.analyze_document("nonexistent.txt")
    
    @patch('src.tools.document_analyzer.logger')
    async def test_analyze_document_logging(self, mock_logger, analyzer, sample_document):
        """æµ‹è¯•ï¼šç¡®ä¿æ­£ç¡®è®°å½•æ—¥å¿—"""
        await analyzer.analyze_document(sample_document)
        mock_logger.info.assert_called_once()
```

### APIå¼€å‘è§„èŒƒ
```python
# æ–‡ä»¶: src/api/document_routes.py

from fastapi import APIRouter, UploadFile, File, HTTPException, Depends
from typing import Dict, Optional
import logging

from ..tools.document_analyzer import DocumentAnalyzer
from ..models.responses import AnalysisResponse
from ..utils.auth import get_current_user

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/documents", tags=["documents"])

@router.post("/analyze", response_model=AnalysisResponse)
async def analyze_document(
    file: UploadFile = File(...),
    options: Optional[Dict] = None,
    current_user = Depends(get_current_user)
):
    """åˆ†æä¸Šä¼ çš„æ–‡æ¡£"""
    
    # éªŒè¯æ–‡ä»¶ç±»å‹
    if not file.filename.endswith(('.txt', '.pdf', '.docx')):
        raise HTTPException(
            status_code=400,
            detail="Unsupported file format"
        )
    
    try:
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        temp_path = f"/tmp/{file.filename}"
        with open(temp_path, "wb") as f:
            content = await file.read()
            f.write(content)
        
        # æ‰§è¡Œåˆ†æ
        analyzer = DocumentAnalyzer()
        result = await analyzer.analyze_document(temp_path, options)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        Path(temp_path).unlink(missing_ok=True)
        
        return AnalysisResponse(
            success=True,
            data=result,
            message="Document analyzed successfully"
        )
        
    except Exception as e:
        logger.error(f"Document analysis failed: {e}")
        raise HTTPException(
            status_code=500,
            detail="Internal server error"
        )
```

## ğŸ§ª æµ‹è¯•å’Œè´¨é‡ä¿è¯

### æµ‹è¯•æ‰§è¡Œæµç¨‹
```bash
# 1. è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# 2. è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
pytest tests/test_document_analyzer.py

# 3. è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=src --cov-report=html

# 4. è¿è¡Œæ€§èƒ½æµ‹è¯•
pytest tests/performance/ -v

# 5. è¿è¡Œé›†æˆæµ‹è¯•
pytest tests/integration/ -v
```

### ä»£ç è´¨é‡æ£€æŸ¥
```bash
# 1. ä»£ç æ ¼å¼åŒ–
black src/ tests/

# 2. å¯¼å…¥æ’åº
isort src/ tests/

# 3. é™æ€ç±»å‹æ£€æŸ¥ï¼ˆå¯é€‰ï¼‰
mypy src/

# 4. ä»£ç å¤æ‚åº¦æ£€æŸ¥
flake8 src/ tests/

# 5. å®‰å…¨æ£€æŸ¥
bandit -r src/
```

### è‡ªåŠ¨åŒ–è´¨é‡æ£€æŸ¥
```bash
# åˆ›å»º Makefile ç®€åŒ–æ“ä½œ
make format      # æ ¼å¼åŒ–ä»£ç 
make lint        # ä»£ç æ£€æŸ¥
make test        # è¿è¡Œæµ‹è¯•
make coverage    # æµ‹è¯•è¦†ç›–ç‡
make quality     # å®Œæ•´è´¨é‡æ£€æŸ¥
```

## ğŸ“¦ éƒ¨ç½²å’Œå‘å¸ƒ

### å¼€å‘ç¯å¢ƒéƒ¨ç½²
```bash
# 1. å¯åŠ¨å¼€å‘æœåŠ¡å™¨
python server.py

# 2. ä½¿ç”¨çƒ­é‡è½½ï¼ˆæ¨èå¼€å‘æ—¶ä½¿ç”¨ï¼‰
uvicorn src.api.app:app --reload --host 0.0.0.0 --port 8000

# 3. åå°è¿è¡Œ
nohup python server.py > app.log 2>&1 &
```

### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
```bash
# 1. æ„å»ºDockeré•œåƒ
docker build -t fusionai:latest .

# 2. è¿è¡Œå®¹å™¨
docker run -d \
  --name fusionai-app \
  -p 8000:8000 \
  -e OPENAI_API_KEY=${OPENAI_API_KEY} \
  -e DATABASE_URL=${DATABASE_URL} \
  fusionai:latest

# 3. ä½¿ç”¨docker-compose
docker-compose up -d
```

### ç‰ˆæœ¬å‘å¸ƒæµç¨‹
```bash
# 1. åˆ›å»ºå‘å¸ƒåˆ†æ”¯
git checkout develop
git pull origin develop
git checkout -b release/v1.2.0

# 2. æ›´æ–°ç‰ˆæœ¬å·
# ç¼–è¾‘ pyproject.toml ä¸­çš„ç‰ˆæœ¬å·

# 3. æ›´æ–°CHANGELOG
# ç¼–è¾‘ CHANGELOG.mdï¼Œæ·»åŠ æ–°ç‰ˆæœ¬çš„å˜æ›´è®°å½•

# 4. æäº¤å‘å¸ƒå‡†å¤‡
git add .
git commit -m "chore: prepare release v1.2.0"

# 5. åˆå¹¶åˆ°ä¸»åˆ†æ”¯
git checkout main
git merge release/v1.2.0

# 6. åˆ›å»ºæ ‡ç­¾
git tag v1.2.0
git push origin main --tags

# 7. åˆå¹¶å›å¼€å‘åˆ†æ”¯
git checkout develop
git merge main
git push origin develop
```

## ğŸ”§ å¸¸ç”¨å¼€å‘å·¥å…·

### IDEé…ç½®å»ºè®®
```json
// .vscode/settings.json
{
    "python.defaultInterpreterPath": "./.venv/bin/python",
    "python.linting.enabled": true,
    "python.linting.pylintEnabled": false,
    "python.linting.flake8Enabled": true,
    "python.formatting.provider": "black",
    "python.testing.pytestEnabled": true,
    "python.testing.pytestArgs": ["tests/"],
    "files.exclude": {
        "**/__pycache__": true,
        "**/.pytest_cache": true,
        "**/node_modules": true
    }
}
```

### Git hooksé…ç½®
```bash
# åˆ›å»ºpre-commit hook
#!/bin/sh
# .git/hooks/pre-commit

echo "Running pre-commit checks..."

# ä»£ç æ ¼å¼åŒ–
black --check src/ tests/
if [ $? -ne 0 ]; then
    echo "Code formatting check failed. Run 'black src/ tests/' to fix."
    exit 1
fi

# è¿è¡Œæµ‹è¯•
pytest tests/ -x
if [ $? -ne 0 ]; then
    echo "Tests failed. Please fix before committing."
    exit 1
fi

echo "All checks passed!"
```

### è°ƒè¯•é…ç½®
```python
# å¼€å‘æ—¶ä½¿ç”¨çš„è°ƒè¯•é…ç½®
import logging
import sys
from pathlib import Path

# é…ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('debug.log')
    ]
)

# è®¾ç½®æ–­ç‚¹è¿›è¡Œè°ƒè¯•
import pdb; pdb.set_trace()

# æˆ–ä½¿ç”¨ipdbï¼ˆæ›´å‹å¥½çš„è°ƒè¯•å™¨ï¼‰
import ipdb; ipdb.set_trace()
```

## ğŸ“š æ–‡æ¡£å’Œæ³¨é‡Š

### ä»£ç æ³¨é‡Šè§„èŒƒ
```python
def complex_business_logic(data: List[Dict], config: Dict) -> ProcessResult:
    """å¤„ç†å¤æ‚çš„ä¸šåŠ¡é€»è¾‘
    
    è¿™ä¸ªå‡½æ•°å®ç°äº†å¤šæ­¥éª¤çš„æ•°æ®å¤„ç†æµç¨‹ï¼š
    1. æ•°æ®éªŒè¯å’Œæ¸…ç†
    2. ä¸šåŠ¡è§„åˆ™åº”ç”¨
    3. ç»“æœæ ¼å¼åŒ–å’ŒéªŒè¯
    
    Args:
        data: è¾“å…¥æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«å¿…è¦çš„ä¸šåŠ¡å­—æ®µ
        config: å¤„ç†é…ç½®ï¼ŒåŒ…å«å¤„ç†å‚æ•°å’Œé€‰é¡¹
        
    Returns:
        ProcessResult: å¤„ç†ç»“æœå¯¹è±¡ï¼ŒåŒ…å«å¤„ç†åçš„æ•°æ®å’Œå…ƒæ•°æ®
        
    Raises:
        ValidationError: æ•°æ®éªŒè¯å¤±è´¥
        ProcessingError: ä¸šåŠ¡å¤„ç†å¼‚å¸¸
        
    Examples:
        >>> data = [{"id": 1, "value": "test"}]
        >>> config = {"strict_mode": True}
        >>> result = complex_business_logic(data, config)
        >>> print(result.success)
        True
    """
    # æ­¥éª¤1: æ•°æ®éªŒè¯
    validated_data = []
    for item in data:
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        if 'id' not in item or 'value' not in item:
            raise ValidationError(f"Missing required fields in item: {item}")
        validated_data.append(item)
    
    # æ­¥éª¤2: åº”ç”¨ä¸šåŠ¡è§„åˆ™
    processed_data = []
    for item in validated_data:
        # æ ¹æ®é…ç½®åº”ç”¨ä¸åŒçš„å¤„ç†é€»è¾‘
        if config.get('strict_mode', False):
            # ä¸¥æ ¼æ¨¡å¼ä¸‹çš„é¢å¤–éªŒè¯
            processed_item = apply_strict_processing(item)
        else:
            # æ ‡å‡†å¤„ç†é€»è¾‘
            processed_item = apply_standard_processing(item)
        
        processed_data.append(processed_item)
    
    # æ­¥éª¤3: æ ¼å¼åŒ–ç»“æœ
    return ProcessResult(
        data=processed_data,
        success=True,
        metadata={
            'processed_count': len(processed_data),
            'config_used': config
        }
    )
```

## ğŸ”— ç›¸å…³è§„åˆ™æ–‡ä»¶
- [git-workflow.mdc](mdc:.cursor/rules/git-workflow.mdc): Gitå·¥ä½œæµè¯¦ç»†æŒ‡å—
- [testing-and-quality.mdc](mdc:.cursor/rules/testing-and-quality.mdc): æµ‹è¯•ç­–ç•¥å’Œè´¨é‡ä¿è¯
- [coding-standards.mdc](mdc:.cursor/rules/coding-standards.mdc): ç¼–ç æ ‡å‡†å’Œè§„èŒƒ
- [api-development.mdc](mdc:.cursor/rules/api-development.mdc): APIå¼€å‘æœ€ä½³å®è·µ
