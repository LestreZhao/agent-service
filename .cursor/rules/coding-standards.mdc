---
description:
globs:
alwaysApply: false
---
# FusionAI ç¼–ç æ ‡å‡†å’Œæœ€ä½³å®è·µ

## ğŸ¯ ç¼–ç åŸåˆ™

### æ ¸å¿ƒç†å¿µ
- **å¯è¯»æ€§ç¬¬ä¸€**: ä»£ç åº”è¯¥åƒæ–‡æ¡£ä¸€æ ·æ˜“è¯»
- **ç®€æ´æ˜äº†**: é¿å…è¿‡åº¦å¤æ‚çš„è®¾è®¡
- **ä¸€è‡´æ€§**: ç»Ÿä¸€çš„ç¼–ç é£æ ¼å’Œæ¨¡å¼
- **å¯æµ‹è¯•æ€§**: ç¼–å†™æ˜“äºæµ‹è¯•çš„ä»£ç 
- **å¯ç»´æŠ¤æ€§**: ä¾¿äºåç»­ä¿®æ”¹å’Œæ‰©å±•

## ğŸ“ ä»£ç æ ¼å¼è§„èŒƒ

### Python é£æ ¼æŒ‡å—
```python
# âœ… æ­£ç¡®çš„å¯¼å…¥é¡ºåº
import os
import sys
from pathlib import Path

import httpx
import pandas as pd
from fastapi import FastAPI
from langchain.agents import Agent

from src.config import settings
from src.tools.base import BaseTool
```

### æ–‡ä»¶å¤´éƒ¨è§„èŒƒ
```python
"""
æ¨¡å—åŠŸèƒ½æè¿°

è¿™ä¸ªæ¨¡å—çš„ä¸»è¦ä½œç”¨æ˜¯...

Author: å¼€å‘è€…å§“å
Created: 2024-01-01
Modified: 2024-01-15
"""

import logging
from typing import Dict, List, Optional, Union

logger = logging.getLogger(__name__)
```

### ç±»å®šä¹‰è§„èŒƒ
```python
class DocumentProcessor(BaseTool):
    """æ–‡æ¡£å¤„ç†å·¥å…·ç±»
    
    æä¾›æ–‡æ¡£è§£æã€å¤„ç†å’Œè½¬æ¢åŠŸèƒ½ã€‚
    æ”¯æŒPDFã€Wordã€Excelç­‰å¤šç§æ ¼å¼ã€‚
    
    Attributes:
        supported_formats: æ”¯æŒçš„æ–‡ä»¶æ ¼å¼åˆ—è¡¨
        max_file_size: æœ€å¤§æ–‡ä»¶å¤§å°é™åˆ¶
        
    Examples:
        >>> processor = DocumentProcessor()
        >>> result = processor.process_file("document.pdf")
        >>> print(result.content)
    """
    
    def __init__(self, max_size: int = 10_000_000):
        """åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨
        
        Args:
            max_size: æœ€å¤§æ–‡ä»¶å¤§å°ï¼Œé»˜è®¤10MB
        """
        super().__init__()
        self.max_file_size = max_size
        self.supported_formats = ['.pdf', '.docx', '.xlsx']
    
    async def process_file(self, file_path: str) -> ProcessResult:
        """å¤„ç†æ–‡æ¡£æ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            ProcessResult: å¤„ç†ç»“æœå¯¹è±¡
            
        Raises:
            FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
            ValueError: ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        """
        # å®ç°é€»è¾‘...
        pass
```

### å‡½æ•°å®šä¹‰è§„èŒƒ
```python
async def fetch_web_content(
    url: str,
    headers: Optional[Dict[str, str]] = None,
    timeout: int = 30,
    max_retries: int = 3
) -> WebContent:
    """è·å–ç½‘é¡µå†…å®¹
    
    ä½¿ç”¨å¼‚æ­¥HTTPå®¢æˆ·ç«¯è·å–ç½‘é¡µå†…å®¹ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶ã€‚
    
    Args:
        url: ç›®æ ‡URL
        headers: å¯é€‰çš„HTTPå¤´éƒ¨
        timeout: è¶…æ—¶æ—¶é—´ï¼Œå•ä½ç§’
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        
    Returns:
        WebContent: åŒ…å«å†…å®¹å’Œå…ƒæ•°æ®çš„å¯¹è±¡
        
    Raises:
        httpx.TimeoutException: è¯·æ±‚è¶…æ—¶
        httpx.HTTPStatusError: HTTPé”™è¯¯çŠ¶æ€
        
    Examples:
        >>> content = await fetch_web_content("https://example.com")
        >>> print(content.text)
    """
    headers = headers or {}
    
    async with httpx.AsyncClient(timeout=timeout) as client:
        for attempt in range(max_retries):
            try:
                response = await client.get(url, headers=headers)
                response.raise_for_status()
                
                return WebContent(
                    url=url,
                    text=response.text,
                    status_code=response.status_code,
                    headers=dict(response.headers)
                )
            except httpx.RequestError as e:
                if attempt == max_retries - 1:
                    raise
                logger.warning(f"Request failed, retrying ({attempt + 1}/{max_retries}): {e}")
                await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
```

## ğŸ”§ é…ç½®å’Œå¸¸é‡ç®¡ç†

### ç¯å¢ƒå˜é‡é…ç½®
```python
# src/config/settings.py
from pydantic import BaseSettings
from typing import Optional

class Settings(BaseSettings):
    """åº”ç”¨é…ç½®è®¾ç½®"""
    
    # API é…ç½®
    openai_api_key: str
    deepseek_api_key: Optional[str] = None
    
    # æ•°æ®åº“é…ç½®
    database_url: str
    db_pool_size: int = 10
    
    # åº”ç”¨é…ç½®
    debug_mode: bool = False
    log_level: str = "INFO"
    
    class Config:
        env_file = ".env"
        case_sensitive = False

settings = Settings()
```

### å¸¸é‡å®šä¹‰
```python
# src/config/constants.py
"""åº”ç”¨å¸¸é‡å®šä¹‰"""

# æ–‡ä»¶ç›¸å…³å¸¸é‡
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB
SUPPORTED_FILE_TYPES = {
    'document': ['.pdf', '.docx', '.txt'],
    'image': ['.jpg', '.jpeg', '.png', '.gif'],
    'data': ['.csv', '.xlsx', '.json']
}

# APIç›¸å…³å¸¸é‡
DEFAULT_TIMEOUT = 30
MAX_RETRIES = 3
RATE_LIMIT_CALLS = 100
RATE_LIMIT_PERIOD = 60  # ç§’

# å“åº”ä»£ç 
class ResponseCode:
    SUCCESS = 200
    BAD_REQUEST = 400
    UNAUTHORIZED = 401
    NOT_FOUND = 404
    INTERNAL_ERROR = 500
```

## ğŸ›¡ï¸ é”™è¯¯å¤„ç†å’Œæ—¥å¿—

### å¼‚å¸¸å¤„ç†æ¨¡å¼
```python
class FusionAIError(Exception):
    """FusionAIåŸºç¡€å¼‚å¸¸ç±»"""
    
    def __init__(self, message: str, error_code: str = None):
        self.message = message
        self.error_code = error_code
        super().__init__(self.message)

class ToolExecutionError(FusionAIError):
    """å·¥å…·æ‰§è¡Œå¼‚å¸¸"""
    pass

class APIError(FusionAIError):
    """APIç›¸å…³å¼‚å¸¸"""
    pass

# ä½¿ç”¨ç¤ºä¾‹
async def execute_tool(tool_name: str, params: dict) -> dict:
    """æ‰§è¡Œå·¥å…·"""
    try:
        tool = get_tool(tool_name)
        result = await tool.execute(params)
        return result
    except KeyError:
        raise ToolExecutionError(
            f"Tool '{tool_name}' not found",
            error_code="TOOL_NOT_FOUND"
        )
    except Exception as e:
        logger.error(f"Tool execution failed: {e}")
        raise ToolExecutionError(
            f"Tool execution failed: {str(e)}",
            error_code="EXECUTION_FAILED"
        )
```

### æ—¥å¿—é…ç½®
```python
# src/config/logging.py
import logging
import sys
from pathlib import Path

def setup_logging(log_level: str = "INFO", log_file: str = None):
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    
    # æ—¥å¿—æ ¼å¼
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    
    # æ–‡ä»¶å¤„ç†å™¨ï¼ˆå¯é€‰ï¼‰
    handlers = [console_handler]
    if log_file:
        file_handler = logging.FileHandler(log_file)
        file_handler.setFormatter(formatter)
        handlers.append(file_handler)
    
    # é…ç½®æ ¹æ—¥å¿—å™¨
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        handlers=handlers
    )
    
    # è®¾ç½®ç¬¬ä¸‰æ–¹åº“æ—¥å¿—çº§åˆ«
    logging.getLogger('httpx').setLevel(logging.WARNING)
    logging.getLogger('urllib3').setLevel(logging.WARNING)
```

## ğŸ§ª æµ‹è¯•è§„èŒƒ

### å•å…ƒæµ‹è¯•ç»“æ„
```python
# tests/test_document_processor.py
import pytest
from pathlib import Path
from unittest.mock import AsyncMock, Mock

from src.tools.document_tool import DocumentProcessor, ProcessResult

class TestDocumentProcessor:
    """æ–‡æ¡£å¤„ç†å™¨æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def processor(self):
        """æµ‹è¯•å¤¹å…·ï¼šåˆ›å»ºæ–‡æ¡£å¤„ç†å™¨å®ä¾‹"""
        return DocumentProcessor(max_size=1_000_000)
    
    @pytest.fixture
    def sample_pdf_path(self, tmp_path):
        """æµ‹è¯•å¤¹å…·ï¼šåˆ›å»ºç¤ºä¾‹PDFæ–‡ä»¶"""
        pdf_file = tmp_path / "sample.pdf"
        pdf_file.write_bytes(b"Sample PDF content")
        return str(pdf_file)
    
    async def test_process_valid_pdf(self, processor, sample_pdf_path):
        """æµ‹è¯•ï¼šå¤„ç†æœ‰æ•ˆçš„PDFæ–‡ä»¶"""
        result = await processor.process_file(sample_pdf_path)
        
        assert isinstance(result, ProcessResult)
        assert result.success is True
        assert result.content is not None
    
    async def test_process_nonexistent_file(self, processor):
        """æµ‹è¯•ï¼šå¤„ç†ä¸å­˜åœ¨çš„æ–‡ä»¶"""
        with pytest.raises(FileNotFoundError):
            await processor.process_file("nonexistent.pdf")
    
    async def test_process_unsupported_format(self, processor, tmp_path):
        """æµ‹è¯•ï¼šå¤„ç†ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"""
        unsupported_file = tmp_path / "file.xyz"
        unsupported_file.write_text("content")
        
        with pytest.raises(ValueError, match="Unsupported file format"):
            await processor.process_file(str(unsupported_file))
```

### é›†æˆæµ‹è¯•ç¤ºä¾‹
```python
# tests/integration/test_api_endpoints.py
import pytest
from fastapi.testclient import TestClient

from src.api.app import app

class TestAPIEndpoints:
    """APIç«¯ç‚¹é›†æˆæµ‹è¯•"""
    
    @pytest.fixture
    def client(self):
        """æµ‹è¯•å®¢æˆ·ç«¯"""
        return TestClient(app)
    
    def test_health_check(self, client):
        """æµ‹è¯•ï¼šå¥åº·æ£€æŸ¥ç«¯ç‚¹"""
        response = client.get("/health")
        assert response.status_code == 200
        assert response.json()["status"] == "healthy"
    
    def test_document_upload(self, client, sample_document):
        """æµ‹è¯•ï¼šæ–‡æ¡£ä¸Šä¼ ç«¯ç‚¹"""
        with open(sample_document, "rb") as f:
            files = {"file": ("test.pdf", f, "application/pdf")}
            response = client.post("/api/documents/upload", files=files)
        
        assert response.status_code == 200
        data = response.json()
        assert "document_id" in data
        assert data["status"] == "uploaded"
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–æŒ‡å—

### å¼‚æ­¥ç¼–ç¨‹æœ€ä½³å®è·µ
```python
# âœ… æ­£ç¡®çš„å¼‚æ­¥å¤„ç†
async def process_multiple_urls(urls: List[str]) -> List[WebContent]:
    """å¹¶å‘å¤„ç†å¤šä¸ªURL"""
    tasks = [fetch_web_content(url) for url in urls]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # å¤„ç†ç»“æœå’Œå¼‚å¸¸
    valid_results = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            logger.error(f"Failed to process {urls[i]}: {result}")
        else:
            valid_results.append(result)
    
    return valid_results

# âœ… ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
async def batch_database_operations(operations: List[dict]):
    """æ‰¹é‡æ•°æ®åº“æ“ä½œ"""
    async with get_db_connection() as conn:
        async with conn.transaction():
            for op in operations:
                await conn.execute(op['query'], op['params'])
```

### ç¼“å­˜ç­–ç•¥
```python
from functools import lru_cache
from typing import Optional
import asyncio

class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        self._cache = {}
        self._lock = asyncio.Lock()
    
    async def get(self, key: str) -> Optional[any]:
        """è·å–ç¼“å­˜å€¼"""
        async with self._lock:
            return self._cache.get(key)
    
    async def set(self, key: str, value: any, ttl: int = 300):
        """è®¾ç½®ç¼“å­˜å€¼"""
        async with self._lock:
            self._cache[key] = {
                'value': value,
                'expires_at': time.time() + ttl
            }
    
    @lru_cache(maxsize=128)
    def get_tool_config(self, tool_name: str) -> dict:
        """è·å–å·¥å…·é…ç½®ï¼ˆå†…å­˜ç¼“å­˜ï¼‰"""
        return load_tool_config(tool_name)
```

## ğŸ”— ç›¸å…³è§„åˆ™æ–‡ä»¶
- [python-best-practices.mdc](mdc:.cursor/rules/python-best-practices.mdc): Pythonæœ€ä½³å®è·µè¯¦è§£
- [testing-and-quality.mdc](mdc:.cursor/rules/testing-and-quality.mdc): æµ‹è¯•ç­–ç•¥æŒ‡å—
- [performance-optimization.mdc](mdc:.cursor/rules/performance-optimization.mdc): æ€§èƒ½ä¼˜åŒ–æŠ€å·§
- [api-development.mdc](mdc:.cursor/rules/api-development.mdc): APIå¼€å‘è§„èŒƒ
